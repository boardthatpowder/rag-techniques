{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Construction: Text-to-metadata-filter\n",
    "\n",
    "![text-to-metadata-filter](../images/images-text-to-metadata-filter.png)\n",
    "\n",
    "**Text-to-Metadata-Filter** is a technique that transforms a user's natural language query into specific metadata criteria, which are then used to filter and retrieve the most relevant documents from a database or document store. This approach enhances the precision of information retrieval by narrowing down search results based on structured metadata attributes such as date, author, category, or tags.\n",
    "\n",
    "**How It Works:**\n",
    "\n",
    "1. **Analyze the Query:**\n",
    "   - The system examines the user's input to identify key elements that correspond to metadata fields.\n",
    "   - *Example:*\n",
    "     - User Query: \"Find recent articles on climate change by Dr. Smith.\"\n",
    "     - Identified Metadata:\n",
    "       - Date: Recent\n",
    "       - Topic: Climate Change\n",
    "       - Author: Dr. Smith\n",
    "\n",
    "2. **Construct Metadata Filters:**\n",
    "   - Based on the analysis, the system creates filters that correspond to the identified metadata.\n",
    "   - *Example:*\n",
    "     - Filters:\n",
    "       - Publication Date: Within the last year\n",
    "       - Author: Dr. Smith\n",
    "       - Subject: Climate Change\n",
    "\n",
    "3. **Apply Filters to Retrieve Documents:**\n",
    "   - The system uses these metadata filters to search the document store, retrieving only those documents that match the specified criteria.\n",
    "   - *Example:*\n",
    "     - Retrieved Documents:\n",
    "       - \"The Impact of Climate Change on Coastal Ecosystems\" by Dr. Smith, published six months ago.\n",
    "       - \"Recent Advances in Climate Change Research\" by Dr. Smith, published three months ago.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- **Precision:** By filtering based on specific metadata, the system retrieves documents that closely match the user's intent, reducing irrelevant results.\n",
    "- **Efficiency:** Narrowing down the search space leads to faster retrieval times and a more streamlined user experience.\n",
    "- **User Satisfaction:** Providing highly relevant results increases user trust and satisfaction with the system.\n",
    "\n",
    "**Advanced Applications:**\n",
    "\n",
    "- **Dynamic Metadata Extraction:** Some systems can automatically extract potential metadata filters from user queries without explicit input. For instance, a query like \"Show me 2022 reports on renewable energy\" can be parsed to apply filters for the year 2022 and the topic \"renewable energy.\" \n",
    "\n",
    "- **Integration with Vector Stores:** In vector databases that support metadata filtering, natural language queries can be translated into structured queries with metadata filters, enhancing retrieval from unstructured documents. \n",
    "\n",
    "**Example in Practice:**\n",
    "\n",
    "Imagine a digital library where each document is tagged with metadata such as author, publication date, and topics covered. A user interested in recent publications by a specific author on a particular subject can have their natural language query converted into metadata filters, allowing the system to efficiently retrieve the most relevant documents.\n",
    "\n",
    "*User Query:*\n",
    "- \"What are the latest research papers on machine learning by Professor Johnson?\"\n",
    "\n",
    "*System Analysis and Filter Construction:*\n",
    "- Author: Professor Johnson\n",
    "- Topic: Machine Learning\n",
    "- Publication Date: Last two years\n",
    "\n",
    "*Retrieved Results:*\n",
    "- \"Advancements in Supervised Learning Techniques\" by Professor Johnson, published in 2023.\n",
    "- \"Deep Learning Architectures for Image Recognition\" by Professor Johnson, published in 2022.\n",
    "\n",
    "By implementing Text-to-Metadata-Filter techniques, systems can significantly enhance the relevance and accuracy of retrieved information, leading to more effective and user-friendly search experiences. \n",
    "\n",
    "![text-to-metadata-filter](../images/text-to-metadata-filter.png)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'enable_langsmith' (bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "%run \"../Z - Common/setup.ipynb\"\n",
    "\n",
    "!pip install -qU arxiv pymupdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use searching Arxiv papers as an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRAPH-CONSTRAINED REASONING: FAITHFUL REA-\n",
      "SONING ON KNOWLEDGE GRAPHS WITH LARGE LAN-\n",
      "GUAGE MODELS\n",
      "Linhao Luo1∗, Zicheng Zhao2∗, Chen Gong2, Gholamreza Haffari1, Shirui Pan3†\n",
      "1Monash University 2Nanjing University of Science and Technology 3Griffith University\n",
      "{Linhao.Luo,Gholamreza.Haffari}@monash.edu\n",
      "{zicheng.zhao,chen.gong}@njust.edu.cn, s.pan@griffith.edu.au\n",
      "ABSTRACT\n",
      "Large language models (LLMs) have demonstrated impressive reasoning abilities,\n",
      "but they still struggle with faithful reasoning due to knowledge gaps and halluci-\n",
      "nations. To address these issues, knowledge graphs (KGs) have been utilized to\n",
      "enhance LLM reasoning through their structured knowledge. However, existing\n",
      "KG-enhanced methods, either retrieval-based or agent-based, encounter difficul-\n",
      "ties in accurately retrieving knowledge and efficiently traversing KGs at scale.\n",
      "In this work, we introduce graph-constrained reasoning (GCR), a novel frame-\n",
      "work that bridges structured knowledge in KGs with unstructured reasoni\n",
      "{'Published': '2024-10-16', 'Title': 'Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models', 'Authors': 'Linhao Luo, Zicheng Zhao, Chen Gong, Gholamreza Haffari, Shirui Pan', 'Summary': 'Large language models (LLMs) have demonstrated impressive reasoning\\nabilities, but they still struggle with faithful reasoning due to knowledge\\ngaps and hallucinations. To address these issues, knowledge graphs (KGs) have\\nbeen utilized to enhance LLM reasoning through their structured knowledge.\\nHowever, existing KG-enhanced methods, either retrieval-based or agent-based,\\nencounter difficulties in accurately retrieving knowledge and efficiently\\ntraversing KGs at scale. In this work, we introduce graph-constrained reasoning\\n(GCR), a novel framework that bridges structured knowledge in KGs with\\nunstructured reasoning in LLMs. To eliminate hallucinations, GCR ensures\\nfaithful KG-grounded reasoning by integrating KG structure into the LLM\\ndecoding process through KG-Trie, a trie-based index that encodes KG reasoning\\npaths. KG-Trie constrains the decoding process, allowing LLMs to directly\\nreason on graphs and generate faithful reasoning paths grounded in KGs.\\nAdditionally, GCR leverages a lightweight KG-specialized LLM for\\ngraph-constrained reasoning alongside a powerful general LLM for inductive\\nreasoning over multiple reasoning paths, resulting in accurate reasoning with\\nzero reasoning hallucination. Extensive experiments on several KGQA benchmarks\\ndemonstrate that GCR achieves state-of-the-art performance and exhibits strong\\nzero-shot generalizability to unseen KGs without additional training.', 'entry_id': 'http://arxiv.org/abs/2410.13080v1', 'published_first_time': '2024-10-16', 'comment': '21 pages, 10 figures', 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL'], 'links': ['http://arxiv.org/abs/2410.13080v1', 'http://arxiv.org/pdf/2410.13080v1']}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "docs = ArxivLoader(\n",
    "    query=\"reasoning\",\n",
    "    load_max_docs=5,\n",
    "    load_all_available_meta=True\n",
    ").load()\n",
    "\n",
    "print(docs[0].page_content[:1000])\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we want to build an index that enables us to:\n",
    "\n",
    "- perform unstructured search over the `Title` and `Summary` attributes of each document\n",
    "- use range filtering on `Published`\n",
    "\n",
    "To convert a natural langauge query into a structured query we need to define a schema for the structured search queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "import datetime\n",
    "\n",
    "class ArxivSearch(BaseModel):\n",
    "    \"\"\"Search over Arxiv documents.\"\"\"\n",
    "\n",
    "    title_search: str = Field(\n",
    "        ...,\n",
    "        description=\"Similarity search query applied to the title.\",\n",
    "    )\n",
    "    summary_search: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"Alternate version of the content search query to apply to summaries. \"\n",
    "            \"Should be succinct and only include key words that could be in a summary.\"\n",
    "        ),\n",
    "    )\n",
    "    earliest_published_date: Optional[datetime.date] = Field(\n",
    "        None,\n",
    "        description=\"Earliest published date filter, inclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    latest_published_date: Optional[datetime.date] = Field(\n",
    "        None,\n",
    "        description=\"Latest published date filter, exclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "\n",
    "\n",
    "    def pretty_print(self) -> None:\n",
    "        for field in self.model_fields:\n",
    "            if getattr(self, field) is not None and getattr(self, field) != getattr(\n",
    "                self.model_fields[field], \"default\", None\n",
    "            ):\n",
    "                print(f\"{field}: {getattr(self, field)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prompt the LLM to produce queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are an expert at converting user questions into database queries. \\\n",
    "You have access to a database of scholarly articles. \\\n",
    "Given a question, return a database query optimized to retrieve the most relevant results.\n",
    "\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "structured_llm = llm.with_structured_output(ArxivSearch)\n",
    "\n",
    "chain_query_analyzer = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_search: LLM autonomous agent system architecture components\n",
      "summary_search: LLM agent system components architecture framework autonomous planning reasoning memory\n"
     ]
    }
   ],
   "source": [
    "chain_query_analyzer.invoke({\"question\": \"What are the main components of an LLM-powered autonomous agent system?\"}).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_search: RAG \"Retrieval Augmented Generation\"\n",
      "summary_search: RAG \"Retrieval Augmented Generation\" LLM retrieval-augmented\n",
      "earliest_published_date: 2024-01-01\n",
      "latest_published_date: 2025-01-01\n"
     ]
    }
   ],
   "source": [
    "chain_query_analyzer.invoke({\"question\": \"what papers on RAG were published in 2024?\"}).pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-techniques",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
