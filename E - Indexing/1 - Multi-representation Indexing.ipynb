{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing: Multi-representation Indexing\n",
    " \n",
    "![multi-representation indexing](../images/images-multi-representation.png)\n",
    "\n",
    "**Multi-Representation Indexing** is a technique that enhances information retrieval systems by creating multiple representations of each document. This approach captures various facets of the document's content, enabling the system to understand and retrieve information more accurately and contextually.\n",
    "\n",
    "**How It Works:**\n",
    "\n",
    "1. **Textual Analysis:**\n",
    "   - Extracts keywords, named entities, or topics from the document.\n",
    "   - *Example:* Identifying that a document contains terms like \"machine learning,\" \"algorithms,\" and \"data analysis.\"\n",
    "\n",
    "2. **Semantic Embeddings:**\n",
    "   - Utilizes language models to capture the document's meaning in a numerical form.\n",
    "   - *Example:* Representing the document's content as a vector that reflects its semantic context.\n",
    "\n",
    "3. **Visual Features (if applicable):**\n",
    "   - Processes images or diagrams within the document to extract visual information.\n",
    "   - *Example:* Analyzing a chart in a research paper to understand its contribution to the document's content.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "- **Improved Retrieval Accuracy:** By incorporating different representations, the system can capture various aspects of the document content, leading to more relevant results for diverse queries.\n",
    "\n",
    "- **Contextual Understanding:** Multi-representation indexing enhances the systemâ€™s ability to understand the context in which terms are used. Semantic representations, such as embeddings from language models, can capture the nuances and relationships between terms, leading to more contextually relevant search results. \n",
    "\n",
    "- **Diverse Query Handling:** The system can effectively process and respond to various queries, including natural language questions, keyword searches, and structured queries.\n",
    "\n",
    "- **Enhanced Flexibility:** Utilizing different representations allows the system to adapt to various document types, such as PDFs, web pages, and databases, as well as varying user needs.\n",
    "\n",
    "- **Handling Complex Information:** Multi-representation indexing can be particularly helpful for documents containing complex information, like scientific papers or code, where textual analysis alone might not be sufficient. \n",
    "\n",
    "**Example in Practice:**\n",
    "\n",
    "Imagine a search engine designed for academic research:\n",
    "\n",
    "- **Document:** A research paper on \"Advancements in Neural Networks.\"\n",
    "\n",
    "- **Representations Created:**\n",
    "  - **Textual Analysis:** Keywords like \"neural networks,\" \"deep learning,\" \"AI.\"\n",
    "  - **Semantic Embedding:** A vector capturing the paper's overall topic and context.\n",
    "  - **Visual Features:** Analysis of included diagrams illustrating neural network architectures.\n",
    "\n",
    "- **User Query:** \"Latest AI techniques in deep learning.\"\n",
    "\n",
    "- **Retrieval Process:**\n",
    "  - The system matches the query against the multiple representations.\n",
    "  - The semantic embedding recognizes the relevance to \"Advancements in Neural Networks.\"\n",
    "  - Textual analysis aligns with keywords like \"AI\" and \"deep learning.\"\n",
    "\n",
    "- **Result:** The research paper is retrieved as a top result due to the comprehensive indexing capturing its relevance from multiple angles.\n",
    "\n",
    "By implementing multi-representation indexing, information retrieval systems can provide more accurate, contextually relevant, and user-tailored search results, enhancing the overall user experience. \n",
    "\n",
    "![Multi-representation Indexing](../images/Multi-representation%20Indexing.png)\n",
    "\n",
    "Arxiv paper:\n",
    "\n",
    "- [Dense X Retrieval: What Retrieval Granularity Should We Use?](https://arxiv.org/pdf/2312.06648)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'enable_langsmith' (bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "%run \"../Z - Common/setup.ipynb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we will use a `MultiVectorRetriever` that retrieves raw documents from an `InMemoryByteStore`, and their summaries from a vector store (Chroma).\n",
    "\n",
    "Let's start by downloading and summarizing docs to seed the database with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\")\n",
    "docs.extend(loader.load())\n",
    "\n",
    "chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "summaries = chain.batch(docs, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, store the summaries in the vector store and the raw documents in the byte store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryByteStore\n",
    "from uuid import uuid4\n",
    "\n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(collection_name=\"summaries\",\n",
    "                     embedding_function=embeddings)\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "byte_store = InMemoryByteStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# The retriever\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=byte_store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "doc_ids = [str(uuid4()) for _ in docs]\n",
    "\n",
    "# Docs linked to summaries\n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]\n",
    "\n",
    "# Add\n",
    "retriever.vectorstore.add_documents(summary_docs)\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try querying both the summary and raw docs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'doc_id': '0d710c7c-4080-4a9f-a785-d2fdf6eff68c'}, page_content=\"Here's a summary of the document on LLM-powered autonomous agents:\\n\\nKey Components:\\n\\n1. Planning\\n- Task decomposition: Breaking complex tasks into manageable subgoals\\n- Self-reflection: Ability to learn from mistakes and refine actions\\n- Uses techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT)\\n\\n2. Memory\\n- Short-term memory: In-context learning with finite context window\\n- Long-term memory: External vector store with fast retrieval\\n- Uses Maximum Inner Product Search (MIPS) algorithms for efficient retrieval\\n\\n3. Tool Use\\n- Enables LLMs to interact with external tools and APIs\\n- Examples include calculators, search engines, code execution, etc.\\n- Frameworks like MRKL and Toolformer help integrate tools\\n\\nNotable Case Studies:\\n- ChemCrow: Domain-specific agent for chemistry tasks\\n- Generative Agents: Simulation of 25 virtual characters interacting\\n- AutoGPT and GPT-Engineer: Proof-of-concept autonomous coding agents\\n\\nKey Challenges:\\n1. Finite context length limiting information processing\\n2. Difficulties with long-term planning and task decomposition\\n3. Reliability issues with natural language interfaces\\n4. Need for better error handling and robustness\\n\\nThe document emphasizes that while LLM-powered agents show promise, there are still significant limitations to overcome before achieving truly autonomous and reliable systems. The field combines various techniques from planning, memory management, and tool integration to create more capable AI agents.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Memory in agents\"\n",
    "sub_docs = vectorstore.similarity_search(query,k=1)\n",
    "sub_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\nLLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(query,n_results=1)\n",
    "retrieved_docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When splitting documents for retrieval, there are often conflicting desires:\n",
    "\n",
    "- You may want to have small documents, so that their embeddings can most accurately reflect their meaning. If too long, then the embeddings can lose meaning.\n",
    "- You want to have long enough documents that the context of each chunk is retained.\n",
    "\n",
    "An alternative to the approach we just implemented for multi-representation indexing is the [ParentDocumentRetriever](https://python.langchain.com/docs/how_to/parent_document_retriever/) that strikes that balance by splitting and storing small chunks of data. During retrieval, it first fetches the small chunks but then looks up the parent ids for those chunks and returns those larger documents.\n",
    "\n",
    "Note that \"parent document\" refers to the document that a small chunk originated from. This can either be the whole raw document OR a larger chunk.\n",
    "\n",
    "> **TODO**: Implement example using `ParentDocumentRetriever`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-techniques",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
