{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing: ColBERT (Contextualized Late Interaction over BERT)\n",
    "\n",
    "![ColBERT](../images/images-ColBERT.png)\n",
    "\n",
    "**ColBERT** is a retrieval model that enhances search efficiency and accuracy by combining the deep language understanding of BERT with a novel interaction mechanism. \n",
    "\n",
    "**How ColBERT Works:**\n",
    "\n",
    "1. **Independent Encoding:**\n",
    "   - Both queries and documents are independently processed through BERT to generate token-level embeddings. \n",
    "\n",
    "2. **Late Interaction Mechanism:**\n",
    "   - Instead of combining query and document embeddings early, ColBERT delays their interaction. It computes similarity scores between each query token embedding and all document token embeddings, capturing fine-grained relationships. \n",
    "\n",
    "3. **MaxSim Operation:**\n",
    "   - For each query token, ColBERT selects the maximum similarity score (MaxSim) from the document tokens, emphasizing the most relevant matches. \n",
    "\n",
    "4. **Aggregation:**\n",
    "   - The model aggregates these maximum similarity scores to produce a final relevance score for ranking documents. \n",
    "\n",
    "**Benefits of ColBERT:**\n",
    "\n",
    "- **Efficiency:** By precomputing document embeddings offline, ColBERT reduces online query processing time, enabling scalable BERT-based search over large text collections in tens of milliseconds. \n",
    "\n",
    "- **Effectiveness:** The fine-grained token-level interactions allow ColBERT to capture nuanced semantic relationships, improving retrieval accuracy. \n",
    "\n",
    "- **Scalability:** ColBERT's architecture supports efficient indexing and retrieval, making it suitable for large-scale information retrieval tasks. \n",
    "\n",
    "**Example in Practice:**\n",
    "\n",
    "Imagine you're searching for information on \"climate change impacts on agriculture.\" ColBERT processes your query and the documents as follows:\n",
    "\n",
    "- **Query Processing:** Each word in your query is encoded into a vector that captures its contextual meaning.\n",
    "\n",
    "- **Document Processing:** Each document is independently encoded into a matrix of token-level embeddings, representing the contextual meaning of each word.\n",
    "\n",
    "- **Similarity Calculation:** ColBERT computes similarity scores between each query token and all document tokens, identifying the most relevant matches.\n",
    "\n",
    "- **Ranking:** Documents are ranked based on the aggregated similarity scores, with higher scores indicating more relevant content.\n",
    "\n",
    "This process enables ColBERT to deliver precise search results by understanding the context and nuances of both the query and the documents.\n",
    "\n",
    "For a more detailed understanding, you can refer to the original research paper on ColBERT: \n",
    "\n",
    "By implementing ColBERT, search systems can achieve a balance between the deep understanding provided by BERT and the efficiency required for large-scale retrieval tasks. \n",
    "\n",
    "The [RAGatouille](https://python.langchain.com/docs/integrations/retrievers/ragatouille/) library includes support for ColBERT.\n",
    "\n",
    "Links:\n",
    "\n",
    "- [ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction)](https://arxiv.org/pdf/2112.01488) paper\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'enable_langsmith' (bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "%run \"../Z - Common/setup.ipynb\"\n",
    "\n",
    "!pip install -qU numpy==1.26.0 tokenizers transformers==4.36.2 faiss-cpu torch ragatouille \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an index we need to load a trained model. This can be one of your own or a pretrained one from the hub! Here we use a pretrained model, then load a couple of documents from wikipedia into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 31, 13:58:06] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[Dec 31, 13:58:07] #> Note: Output directory .ragatouille/colbert/indexes/my_index already exists\n",
      "\n",
      "\n",
      "[Dec 31, 13:58:07] #> Will delete 10 files already at .ragatouille/colbert/indexes/my_index in 20 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 31, 13:58:28] [0] \t\t #> Encoding 178 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "100%|██████████| 6/6 [00:12<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 31, 13:58:40] [0] \t\t avg_doclen_est = 131.20787048339844 \t len(local_sample) = 178\n",
      "[Dec 31, 13:58:40] [0] \t\t Creating 2,048 partitions.\n",
      "[Dec 31, 13:58:40] [0] \t\t *Estimated* 23,355 embeddings.\n",
      "[Dec 31, 13:58:40] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/my_index/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/colbert/indexing/collection_indexer.py:256: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sub_sample = torch.load(sub_sample_path)\n",
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  centroids = torch.load(centroids_path, map_location='cpu')\n",
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  avg_residual = torch.load(avgresidual_path, map_location='cpu')\n",
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/colbert/indexing/codecs/residual.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bucket_cutoffs, bucket_weights = torch.load(buckets_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used 17 iterations (1.9021s) to cluster 22188 items into 2048 clusters\n",
      "[0.036, 0.037, 0.038, 0.033, 0.03, 0.035, 0.032, 0.034, 0.032, 0.033, 0.032, 0.035, 0.033, 0.034, 0.033, 0.037, 0.03, 0.031, 0.032, 0.035, 0.033, 0.033, 0.033, 0.034, 0.034, 0.03, 0.036, 0.033, 0.033, 0.033, 0.033, 0.037, 0.036, 0.033, 0.032, 0.032, 0.033, 0.032, 0.034, 0.037, 0.033, 0.036, 0.033, 0.031, 0.034, 0.033, 0.032, 0.034, 0.035, 0.033, 0.032, 0.034, 0.032, 0.034, 0.034, 0.034, 0.035, 0.037, 0.038, 0.03, 0.032, 0.034, 0.031, 0.033, 0.035, 0.033, 0.034, 0.036, 0.03, 0.032, 0.033, 0.031, 0.032, 0.035, 0.035, 0.033, 0.033, 0.036, 0.033, 0.036, 0.033, 0.036, 0.031, 0.037, 0.031, 0.032, 0.035, 0.033, 0.032, 0.04, 0.032, 0.034, 0.033, 0.035, 0.035, 0.033, 0.037, 0.033, 0.034, 0.035, 0.036, 0.038, 0.035, 0.033, 0.036, 0.034, 0.033, 0.032, 0.034, 0.03, 0.033, 0.034, 0.034, 0.031, 0.035, 0.033, 0.034, 0.033, 0.035, 0.036, 0.031, 0.031, 0.034, 0.035, 0.032, 0.035, 0.035, 0.035]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 31, 13:58:42] [0] \t\t #> Encoding 178 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:12<00:00,  2.14s/it]\n",
      "1it [00:13, 13.07s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/colbert/indexing/codecs/residual_embeddings.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(codes_path, map_location='cpu')\n",
      "100%|██████████| 1/1 [00:00<00:00, 537.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 31, 13:58:55] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Dec 31, 13:58:55] #> Building the emb2pid mapping..\n",
      "[Dec 31, 13:58:55] len(emb2pid) = 23355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2048/2048 [00:00<00:00, 92815.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 31, 13:58:55] #> Saved optimized IVF to .ragatouille/colbert/indexes/my_index/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ragatouille import RAGPretrainedModel\n",
    "from ragatouille.utils import get_wikipedia_page\n",
    "\n",
    "rag = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "docs = [get_wikipedia_page(\"Hayao_Miyazaki\"), get_wikipedia_page(\"Studio_Ghibli\")]\n",
    "colbert_index_path = rag.index(\n",
    "    collection=docs,\n",
    "    index_name=\"my_index\", \n",
    "    max_document_length=180,\n",
    "    split_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index my_index for the first time... This may take a few seconds\n",
      "[Dec 31, 13:58:57] #> Loading codec...\n",
      "[Dec 31, 13:58:57] #> Loading IVF...\n",
      "[Dec 31, 13:58:57] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/colbert/search/index_loader.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ivf, ivf_lengths = torch.load(os.path.join(self.index_path, \"ivf.pid.pt\"), map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 31, 13:58:57] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4429.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 31, 13:58:57] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/colbert/indexing/codecs/residual_embeddings.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(codes_path, map_location='cpu')\n",
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/colbert/indexing/codecs/residual_embeddings.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(residuals_path, map_location='cpu')\n",
      "100%|██████████| 1/1 [00:00<00:00, 196.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 31, 13:58:57] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dec 31, 13:58:57] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What animation studio did Miyazaki found?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  7284,  2996,  2106,  2771,  3148, 18637,  2179,\n",
      "         1029,   102,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'content': '=== Studio Ghibli ===\\n\\n\\n==== Early films (1985–1995) ====\\nFollowing the success of Nausicaä of the Valley of the Wind, Miyazaki and Takahata founded the animation production company Studio Ghibli on June 15, 1985, as a subsidiary of Tokuma Shoten, with offices in Kichijōji designed by Miyazaki. Miyazaki named the studio after the Caproni Ca.309 and the Italian word meaning \"a hot wind that blows in the desert\"; the name had been registered a year earlier.',\n",
       "  'score': 25.885944366455078,\n",
       "  'rank': 1,\n",
       "  'document_id': 'ad85c72e-6e24-423b-9ecf-75b9fbe31273',\n",
       "  'passage_id': 42},\n",
       " {'content': 'Hayao Miyazaki (宮崎 駿 or 宮﨑 駿, Miyazaki Hayao, [mijaꜜzaki hajao]; born January 5, 1941) is a Japanese animator, filmmaker, and manga artist. He co-founded Studio Ghibli and serves as its honorary chairman. Over the course of his career, Miyazaki has attained international acclaim as a masterful storyteller and creator of Japanese animated feature films, and is widely regarded as one of the most accomplished filmmakers in the history of animation.\\nBorn in Tokyo City, Miyazaki expressed interest in manga and animation from an early age.',\n",
       "  'score': 25.479787826538086,\n",
       "  'rank': 2,\n",
       "  'document_id': 'ad85c72e-6e24-423b-9ecf-75b9fbe31273',\n",
       "  'passage_id': 0},\n",
       " {'content': 'On November 7, 2014, Miyazaki stated, \"That was not my intention, though. All I did was announce that I would be retiring and not making any more features.\" Lead producer Yoshiaki Nishimura among several other staffers from Ghibli, such as director Hiromasa Yonebayashi, left to found Studio Ponoc in April 2015, working on the film Mary and the Witch\\'s Flower.\\nThe 2016 animated fantasy film The Red Turtle, directed and co-written by Dutch-British animator Michaël Dudok de Wit in his feature film debut, was a co-production between Studio Ghibli and Wild Bunch.\\nIn February 2017, Toshio Suzuki announced that Hayao Miyazaki had come out of retirement to direct a new feature film with Studio Ghibli.',\n",
       "  'score': 25.356061935424805,\n",
       "  'rank': 3,\n",
       "  'document_id': '1df2d7fc-cb09-40c2-866f-1c5d5886cf22',\n",
       "  'passage_id': 137}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = rag.search(query=\"What animation studio did Miyazaki found?\", k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then convert easily to a LangChain retriever! We can pass in any kwargs we want when creating (like k):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='=== Studio Ghibli ===\\n\\n\\n==== Early films (1985–1995) ====\\nFollowing the success of Nausicaä of the Valley of the Wind, Miyazaki and Takahata founded the animation production company Studio Ghibli on June 15, 1985, as a subsidiary of Tokuma Shoten, with offices in Kichijōji designed by Miyazaki. Miyazaki named the studio after the Caproni Ca.309 and the Italian word meaning \"a hot wind that blows in the desert\"; the name had been registered a year earlier.'),\n",
       " Document(metadata={}, page_content='Hayao Miyazaki (宮崎 駿 or 宮﨑 駿, Miyazaki Hayao, [mijaꜜzaki hajao]; born January 5, 1941) is a Japanese animator, filmmaker, and manga artist. He co-founded Studio Ghibli and serves as its honorary chairman. Over the course of his career, Miyazaki has attained international acclaim as a masterful storyteller and creator of Japanese animated feature films, and is widely regarded as one of the most accomplished filmmakers in the history of animation.\\nBorn in Tokyo City, Miyazaki expressed interest in manga and animation from an early age.'),\n",
       " Document(metadata={}, page_content='On November 7, 2014, Miyazaki stated, \"That was not my intention, though. All I did was announce that I would be retiring and not making any more features.\" Lead producer Yoshiaki Nishimura among several other staffers from Ghibli, such as director Hiromasa Yonebayashi, left to found Studio Ponoc in April 2015, working on the film Mary and the Witch\\'s Flower.\\nThe 2016 animated fantasy film The Red Turtle, directed and co-written by Dutch-British animator Michaël Dudok de Wit in his feature film debut, was a co-production between Studio Ghibli and Wild Bunch.\\nIn February 2017, Toshio Suzuki announced that Hayao Miyazaki had come out of retirement to direct a new feature film with Studio Ghibli.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = rag.as_langchain_retriever(k=3)\n",
    "\n",
    "retriever.invoke(\"What animation studio did Miyazaki found?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily combine this retriever in to a chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from pprint import pprint\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "# pprint(prompt)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Miyazaki co-founded Studio Ghibli on June 15, 1985, along with Isao Takahata, as a subsidiary of Tokuma Shoten. The studio was named after the Caproni Ca.309 and the Italian word meaning \"a hot wind that blows in the desert.\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What animation studio did Miyazaki found?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-techniques",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
