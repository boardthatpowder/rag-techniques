{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Translation: Decomposition\n",
    "\n",
    "![decomposition](../images/images-decomposition.png)\n",
    "\n",
    "**Decomposition** is a technique to handle complex or multi-part queries by breaking them down into smaller, simpler pieces. Each part is processed independently, and the results are combined to generate a final response. Let’s make this simple:\n",
    "\n",
    "### The Problem Decomposition Solves\n",
    "When you ask a RAG system a question that has multiple parts or is too complex, the system might:\n",
    "- Struggle to understand the full intent.\n",
    "- Retrieve information that is incomplete or irrelevant because it can’t focus on each aspect of the query.\n",
    "\n",
    "**Decomposition** addresses this by splitting the query into manageable pieces, so each part can be processed more effectively.\n",
    "\n",
    "### How Decomposition Works\n",
    "1. **Break Down the Query**:\n",
    "   - The system splits the original query into smaller, independent sub-queries. Each sub-query targets one specific aspect of the original question.\n",
    "   - Example:\n",
    "     - Original Query: \"What are the best practices for securing APIs, and how does OAuth 2.0 work?\"\n",
    "     - Sub-Queries:\n",
    "       - \"What are the best practices for securing APIs?\"\n",
    "       - \"How does OAuth 2.0 work?\"\n",
    "\n",
    "2. **Retrieve for Each Sub-Query**:\n",
    "   - Each sub-query is sent to the retriever to fetch relevant documents or information.\n",
    "   - Example:\n",
    "     - For \"best practices for securing APIs,\" it retrieves documents on general API security.\n",
    "     - For \"how OAuth 2.0 works,\" it retrieves documents explaining the OAuth 2.0 framework.\n",
    "\n",
    "3. **Combine Retrieved Information**:\n",
    "   - The retrieved documents or information for all sub-queries are combined into a single context for the next step.\n",
    "\n",
    "4. **Generate the Response**:\n",
    "   - The combined information is passed to the LLM, which uses it to generate a comprehensive and coherent response to the original query.\n",
    "\n",
    "### Why Decomposition Works\n",
    "- **Simplifies Complexity**: By breaking a complex question into simpler parts, it becomes easier to retrieve relevant information for each part.\n",
    "- **Improves Focus**: Each sub-query is more focused, reducing the chances of retrieving irrelevant documents.\n",
    "- **Combines Expertise**: Allows the system to handle different aspects of a query with equal attention, leading to more complete answers.\n",
    "\n",
    "### Simple Example\n",
    "#### Query:\n",
    "*\"What are the top API security measures, and how do they differ for REST and GraphQL APIs?\"*\n",
    "\n",
    "#### Without Decomposition:\n",
    "- The system might retrieve general API security documents without addressing the specific REST vs. GraphQL distinction.\n",
    "\n",
    "#### With Decomposition:\n",
    "1. Sub-Queries:\n",
    "   - \"What are the top API security measures?\"\n",
    "   - \"What are the security considerations for REST APIs?\"\n",
    "   - \"What are the security considerations for GraphQL APIs?\"\n",
    "\n",
    "2. Retrieved Documents:\n",
    "   - For Sub-Query 1: General security guidelines like OAuth, input validation.\n",
    "   - For Sub-Query 2: REST-specific guidelines like rate limiting.\n",
    "   - For Sub-Query 3: GraphQL-specific considerations like query depth limiting.\n",
    "\n",
    "3. Combined Information:\n",
    "   - A mix of general security practices and specific guidance for REST and GraphQL.\n",
    "\n",
    "4. Final Output:\n",
    "   - A response like: \"Top API security measures include OAuth 2.0, input validation, and HTTPS enforcement. For REST APIs, rate limiting and endpoint validation are crucial, while for GraphQL APIs, query depth and complexity limiting are important to prevent abuse.\"\n",
    "\n",
    "### Key Benefits of Decomposition\n",
    "- **Handles Complexity**: Effectively answers multi-part or detailed queries.\n",
    "- **Complete Responses**: Ensures all aspects of the query are addressed.\n",
    "- **Better Retrieval**: Each sub-query retrieves more focused and relevant results.\n",
    "\n",
    "In short, **Decomposition** is like breaking a big question into smaller, easier-to-answer questions, retrieving information for each, and piecing it all together to provide a thorough response!\n",
    "\n",
    "![decomposition_recursive](../images/decomposition_recursive.png)\n",
    "\n",
    "Arxiv papers:\n",
    "\n",
    "- [Least-to-Most Prompting Enables Complex Reasoning in Large Language Models](https://arxiv.org/pdf/2205.10625)\n",
    "- [Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions](https://arxiv.org/pdf/2212.10509)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../Z - Common/setup.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_sample_data()\n",
    "split_docs = split_sample_data(docs)\n",
    "retriever = seed_sample_data(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating the prompt and chain to generate the initial decomposed sub-questions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Generate 5 search queries related to: {question} \\n\n",
    "Return the queries only as text only, each separated with a new line character.\"\"\"\n",
    "\n",
    "prompt_generate_queries = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain_generate_queries = ( \n",
    "                          prompt_generate_queries \n",
    "                          | llm\n",
    "                          | StrOutputParser() \n",
    "                          | (lambda x: x.split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['components of LLM agent architecture',\n",
       " 'difference between LLM and autonomous agent system',\n",
       " 'key modules needed for LLM agent decision making',\n",
       " 'memory and planning systems in LLM agents',\n",
       " 'tools and APIs integration in autonomous LLM agents']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the main components of an LLM-powered autonomous agent system?\"\n",
    "decomposed_questions = chain_generate_queries.invoke({\"question\":question})\n",
    "\n",
    "decomposed_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the prompt to answer the original question based on the additional context gathered via the decomposition chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Here is the question you need to answer:\n",
    "\n",
    "\\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "Here is any available background question + answer pairs:\n",
    "\n",
    "\\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "Here is additional context relevant to the question: \n",
    "\n",
    "\\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt_solve_recursively = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an additional chain that takes the `decomposed_questions` and solves using the above prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qa_pair_recursive(question, answer):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def retrieve_and_rag_recursive(decomposed_questions):\n",
    "    q_a_pairs = \"\"\n",
    "    for q in decomposed_questions:\n",
    "        \n",
    "        rag_chain = (\n",
    "            {\"context\": itemgetter(\"question\") | retriever, \n",
    "            \"question\": itemgetter(\"question\"),\n",
    "            \"q_a_pairs\": itemgetter(\"q_a_pairs\")} \n",
    "            | prompt_solve_recursively\n",
    "            | llm\n",
    "            | StrOutputParser())\n",
    "\n",
    "        answer = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
    "        q_a_pair = format_qa_pair_recursive(q,answer)\n",
    "        q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair\n",
    "        \n",
    "    return (answer, q_a_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the available context and background information, I'll explain tools and APIs integration in autonomous LLM agents:\n",
      "\n",
      "Key Aspects of Tool and API Integration:\n",
      "\n",
      "1. Core Integration Components\n",
      "- API connections to external tools and services\n",
      "- Tool selection and usage logic\n",
      "- Output parsing and handling mechanisms\n",
      "- Interface management between LLM and external tools\n",
      "\n",
      "2. Functional Integration\n",
      "- Allows the LLM agent to interact with external systems\n",
      "- Enables real-world actions beyond just language processing\n",
      "- Provides access to additional capabilities and data sources\n",
      "- Helps bridge the gap between reasoning and actual task execution\n",
      "\n",
      "3. Integration Architecture\n",
      "- Tool selection module to choose appropriate tools for tasks\n",
      "- API connectors to establish connections with external services\n",
      "- Output handlers to process and interpret tool responses\n",
      "- Error handling mechanisms for failed interactions\n",
      "- Data formatters to ensure proper communication between systems\n",
      "\n",
      "4. Key Benefits\n",
      "- Extends the agent's capabilities beyond language processing\n",
      "- Enables practical task execution in real-world scenarios\n",
      "- Provides access to up-to-date information and services\n",
      "- Allows for dynamic interaction with external systems\n",
      "\n",
      "5. Integration Considerations\n",
      "- Security and authentication management\n",
      "- Rate limiting and resource optimization\n",
      "- Error handling and recovery procedures\n",
      "- Data format compatibility\n",
      "- API version management\n",
      "\n",
      "The integration of tools and APIs is crucial for transforming an LLM from a pure language model into a practical autonomous agent capable of real-world interactions and task execution. This integration forms a bridge between the agent's planning and reasoning capabilities and its ability to effect change in the external world.\n",
      "\n",
      "---\n",
      "Question: components of LLM agent architecture\n",
      "Answer: Based on the limited context provided, I'll outline the key components typically found in LLM agent architectures:\n",
      "\n",
      "1. Language Model Core\n",
      "- The foundation LLM that powers the agent's reasoning and text generation capabilities\n",
      "- Can be GPT, LLaMA, or other large language models\n",
      "\n",
      "2. Memory Systems\n",
      "- Short-term working memory to maintain context\n",
      "- Long-term memory storage for persistent knowledge\n",
      "- Episodic memory for remembering past interactions\n",
      "\n",
      "3. Planning & Reasoning Module\n",
      "- Goal setting and decomposition\n",
      "- Task planning and sequencing\n",
      "- Decision making capabilities\n",
      "\n",
      "4. Tool Integration\n",
      "- API connections to external tools and services\n",
      "- Tool selection and usage logic\n",
      "- Output parsing and handling\n",
      "\n",
      "5. Input/Output Interfaces\n",
      "- Natural language understanding\n",
      "- Response generation\n",
      "- User interaction handling\n",
      "\n",
      "6. Control Flow\n",
      "- Execution monitoring\n",
      "- Error handling\n",
      "- Loop and iteration management\n",
      "\n",
      "7. Knowledge Base\n",
      "- Access to reference information\n",
      "- Domain-specific knowledge\n",
      "- Contextual information\n",
      "\n",
      "8. Safety & Control Mechanisms\n",
      "- Output filtering\n",
      "- Boundary enforcement\n",
      "- Safety checks\n",
      "\n",
      "Note: While the provided context is very limited, this represents a general architecture of LLM-based agents based on common implementations. The exact components may vary depending on the specific agent's purpose and design.\n",
      "---\n",
      "Question: difference between LLM and autonomous agent system\n",
      "Answer: Based on the provided context, here are the key differences between an LLM and an autonomous agent system:\n",
      "\n",
      "1. Core Function vs Complete System\n",
      "- LLM: A language model that primarily processes and generates text based on input\n",
      "- Autonomous Agent System: Uses an LLM as its \"brain\" but includes multiple additional components and capabilities\n",
      "\n",
      "2. Components and Architecture\n",
      "- LLM: Standalone model focused on language processing\n",
      "- Autonomous Agent System: Comprehensive system that includes:\n",
      "  - The core LLM\n",
      "  - Planning capabilities\n",
      "  - Memory systems\n",
      "  - Tool integration\n",
      "  - Control mechanisms\n",
      "  - Goal-setting abilities\n",
      "\n",
      "3. Capabilities\n",
      "- LLM: Focused on language understanding and generation tasks\n",
      "- Autonomous Agent System: Can:\n",
      "  - Break down complex tasks into subgoals\n",
      "  - Perform self-reflection and refinement\n",
      "  - Learn from past actions\n",
      "  - Execute multi-step tasks\n",
      "  - Interact with external tools and systems\n",
      "\n",
      "4. Purpose\n",
      "- LLM: Primarily designed for language-based tasks and generation\n",
      "- Autonomous Agent System: Functions as a general problem solver that can plan, execute, and improve its actions over time\n",
      "\n",
      "In essence, an LLM is just one component (albeit a central one) of an autonomous agent system. The agent system builds upon the LLM's capabilities by adding crucial features like planning, memory, and self-improvement mechanisms to create a more complete and autonomous problem-solving system.\n",
      "---\n",
      "Question: key modules needed for LLM agent decision making\n",
      "Answer: Based on the provided context and background information, here are the key modules needed for LLM agent decision making:\n",
      "\n",
      "1. Planning Module\n",
      "- Subgoal decomposition capabilities to break down complex tasks\n",
      "- Task planning and sequencing functionality\n",
      "- Reflection and refinement mechanisms for self-improvement\n",
      "- Goal setting and management\n",
      "\n",
      "2. Memory Systems\n",
      "- Short-term working memory for current context\n",
      "- Long-term memory for persistent knowledge\n",
      "- Episodic memory to learn from past actions and decisions\n",
      "\n",
      "3. Core Language Model\n",
      "- The foundation LLM that serves as the \"brain\"\n",
      "- Handles reasoning and decision-making processes\n",
      "- Processes input and generates responses\n",
      "\n",
      "4. Control Mechanisms\n",
      "- Execution monitoring\n",
      "- Error handling\n",
      "- Safety checks and boundaries\n",
      "- Decision validation\n",
      "\n",
      "5. Knowledge Integration\n",
      "- Access to reference information\n",
      "- Domain-specific knowledge bases\n",
      "- Contextual information processing\n",
      "\n",
      "These modules work together to enable effective decision-making by:\n",
      "- Breaking down complex decisions into manageable parts\n",
      "- Learning from past experiences stored in memory\n",
      "- Applying reasoning through the LLM core\n",
      "- Monitoring and validating decisions\n",
      "- Refining approaches through self-reflection\n",
      "\n",
      "The combination of these modules allows the agent to make informed, contextual decisions while maintaining the ability to learn and improve from experience.\n",
      "---\n",
      "Question: memory and planning systems in LLM agents\n",
      "Answer: Based on the provided context and background information, here's an analysis of memory and planning systems in LLM agents:\n",
      "\n",
      "Memory Systems:\n",
      "\n",
      "1. Observation Storage\n",
      "- Stores direct observations and events experienced by the agent\n",
      "- Includes inter-agent communications and natural language statements\n",
      "\n",
      "2. Retrieval Model with Three Key Factors:\n",
      "- Recency: Higher priority given to recent events/memories\n",
      "- Importance: Distinguishes between mundane and core memories (evaluated by the LLM)\n",
      "- Relevance: Ranks memories based on relation to current situation/query\n",
      "\n",
      "3. Reflection Mechanism\n",
      "- Synthesizes memories into higher-level inferences\n",
      "- Processes the 100 most recent observations\n",
      "- Generates and answers salient high-level questions\n",
      "- Creates higher-level summaries of past events\n",
      "\n",
      "Planning Systems:\n",
      "\n",
      "1. Core Planning Components\n",
      "- Translates reflections and environmental information into actions\n",
      "- Optimizes for both immediate and long-term believability\n",
      "- Uses prompt templates to structure planning (e.g., \"Here is X's plan today in broad strokes:\")\n",
      "\n",
      "2. Environmental Considerations\n",
      "- Processes information in a tree structure\n",
      "- Accounts for relationships between agents\n",
      "- Incorporates observations of other agents\n",
      "\n",
      "3. Integration with Memory\n",
      "- Uses retrieved context to inform behavior\n",
      "- Leverages reflections for future planning\n",
      "- Considers past experiences in decision-making\n",
      "\n",
      "The memory and planning systems work together symbiotically:\n",
      "- Memory provides context and learning from past experiences\n",
      "- Planning uses this information to make informed decisions\n",
      "- Reflection mechanisms bridge memory and planning by creating higher-level insights\n",
      "- The system continuously updates and refines based on new observations and experiences\n",
      "\n",
      "This integrated approach allows LLM agents to maintain context, learn from experience, and make informed decisions while considering both immediate and long-term goals.\n",
      "---\n",
      "Question: tools and APIs integration in autonomous LLM agents\n",
      "Answer: Based on the available context and background information, I'll explain tools and APIs integration in autonomous LLM agents:\n",
      "\n",
      "Key Aspects of Tool and API Integration:\n",
      "\n",
      "1. Core Integration Components\n",
      "- API connections to external tools and services\n",
      "- Tool selection and usage logic\n",
      "- Output parsing and handling mechanisms\n",
      "- Interface management between LLM and external tools\n",
      "\n",
      "2. Functional Integration\n",
      "- Allows the LLM agent to interact with external systems\n",
      "- Enables real-world actions beyond just language processing\n",
      "- Provides access to additional capabilities and data sources\n",
      "- Helps bridge the gap between reasoning and actual task execution\n",
      "\n",
      "3. Integration Architecture\n",
      "- Tool selection module to choose appropriate tools for tasks\n",
      "- API connectors to establish connections with external services\n",
      "- Output handlers to process and interpret tool responses\n",
      "- Error handling mechanisms for failed interactions\n",
      "- Data formatters to ensure proper communication between systems\n",
      "\n",
      "4. Key Benefits\n",
      "- Extends the agent's capabilities beyond language processing\n",
      "- Enables practical task execution in real-world scenarios\n",
      "- Provides access to up-to-date information and services\n",
      "- Allows for dynamic interaction with external systems\n",
      "\n",
      "5. Integration Considerations\n",
      "- Security and authentication management\n",
      "- Rate limiting and resource optimization\n",
      "- Error handling and recovery procedures\n",
      "- Data format compatibility\n",
      "- API version management\n",
      "\n",
      "The integration of tools and APIs is crucial for transforming an LLM from a pure language model into a practical autonomous agent capable of real-world interactions and task execution. This integration forms a bridge between the agent's planning and reasoning capabilities and its ability to effect change in the external world.\n"
     ]
    }
   ],
   "source": [
    "result_recursive,q_a_pairs = retrieve_and_rag_recursive(decomposed_questions)\n",
    "\n",
    "print(result_recursive)\n",
    "print(q_a_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at how to perform decomposition individually.\n",
    "\n",
    "![decomposition_individually](../images/decomposition_individually.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_rag_individually(question,prompt_rag,sub_question_generator_chain):\n",
    "    \"\"\"RAG on each sub-question\"\"\"\n",
    "    \n",
    "    # Use our decomposition / \n",
    "    sub_questions = sub_question_generator_chain.invoke({\"question\":question})\n",
    "    \n",
    "    # Initialize a list to hold RAG chain results\n",
    "    rag_results = []\n",
    "    \n",
    "    for sub_question in sub_questions:\n",
    "        \n",
    "        # Retrieve documents for each sub-question\n",
    "        retrieved_docs = retriever.invoke(sub_question)\n",
    "        \n",
    "        # Use retrieved documents and sub-question in RAG chain\n",
    "        answer = (\n",
    "            prompt_rag \n",
    "            | llm\n",
    "            | StrOutputParser()).invoke({\"context\": retrieved_docs, \"question\": sub_question})\n",
    "        rag_results.append(answer)\n",
    "    \n",
    "    return rag_results,sub_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers:\n",
      "['I apologize, but I cannot provide a complete answer about the components of LLM agent architecture based on the given context. The provided context only mentions that there are limitations to LLM-centered agents but does not describe their components.', 'LLM agents use large language models as their core controller or \"brain,\" while traditional AI agents typically rely on more rigid, rule-based systems. LLM agents can break down complex tasks into subgoals and have the ability to perform self-reflection and learning from mistakes. Additionally, LLM agents are more flexible general problem solvers that can handle a wider range of tasks, from writing to programming to complex reasoning.', \"Based on the provided context, I cannot provide specific details about memory systems in LLM-powered autonomous agents. While the context mentions memory as one of the key components of LLM-powered autonomous agent systems, it doesn't elaborate on the memory systems themselves.\", \"LLM agents can handle planning and reasoning in different ways: ReAct integrates reasoning and acting by combining task-specific actions with language-based reasoning traces, while LLM+P uses an external classical planner with PDDL (Planning Domain Definition Language) for long-horizon planning. Both approaches aim to enhance the agent's decision-making capabilities, with ReAct focusing on integrated reasoning and LLM+P relying on external planning tools.\", \"In autonomous LLM systems, input/output handling isn't directly addressed in the provided context. The context mainly discusses LLMs as core controllers and mentions components like planning and memory, but doesn't specifically cover I/O handling. I cannot provide a specific answer about input/output handling based on the given context.\"]\n",
      "Questions:\n",
      "['components of LLM agent architecture', 'difference between LLM agents and traditional AI agents', 'memory systems in LLM-powered autonomous agents', 'planning and reasoning modules in LLM agents', 'input/output handling in autonomous LLM systems']\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "answers, questions = retrieve_and_rag_individually(question, prompt, chain_generate_queries)\n",
    "\n",
    "print(\"Answers:\")\n",
    "print(answers)\n",
    "\n",
    "print(\"Questions:\")\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the final chain to perform decomposition individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### QUERY TRANSLATION - Decomposition - utility function ####\n",
    "\n",
    "def format_qa_pairs_individually(questions, answers):\n",
    "    \"\"\"Format Q and A pairs\"\"\"\n",
    "    \n",
    "    formatted_string = \"\"\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
    "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "context = format_qa_pairs_individually(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### QUERY TRANSLATION - Decomposition - prompt an chain individually ####\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Here is a set of Q+A pairs:\n",
    "\n",
    "{context}\n",
    "\n",
    "Use these to synthesize an answer to the question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt_solve_individually = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain_solve_individually = (\n",
    "    prompt_solve_individually\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Based on the Q+A pairs provided, I can synthesize that LLM-powered '\n",
      " 'autonomous agent systems have several main components:\\n'\n",
      " '\\n'\n",
      " '1. Core Controller/Brain: The LLM itself serves as the central controller, '\n",
      " 'providing more flexible and general problem-solving capabilities compared to '\n",
      " 'traditional rule-based systems.\\n'\n",
      " '\\n'\n",
      " '2. Planning and Reasoning Modules: These can be implemented in different '\n",
      " 'ways:\\n'\n",
      " '- ReAct approach: Integrates reasoning and acting through combined '\n",
      " 'task-specific actions and language-based reasoning\\n'\n",
      " '- LLM+P approach: Uses external classical planners with PDDL for '\n",
      " 'long-horizon planning\\n'\n",
      " '\\n'\n",
      " \"3. Memory Systems: While specific details aren't provided, memory is \"\n",
      " 'mentioned as a key component of these systems.\\n'\n",
      " '\\n'\n",
      " '4. Task Management: The system can break down complex tasks into subgoals '\n",
      " 'and includes capabilities for self-reflection and learning from mistakes.\\n'\n",
      " '\\n'\n",
      " \"However, it's worth noting that some aspects, such as specific details about \"\n",
      " 'memory systems and input/output handling, are not fully detailed in the '\n",
      " 'source material. The architecture appears to be built around the LLM as the '\n",
      " 'core component, with supporting systems for planning, reasoning, and memory '\n",
      " 'management to enable autonomous operation.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "result_individually=chain_solve_individually.invoke({\"context\":context,\"question\":question})\n",
    "\n",
    "pprint(result_individually)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results so we can compare later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "write_results(\"decomposition-recursive.txt\", result_recursive)\n",
    "write_results(\"decomposition-individually.txt\", result_individually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-techniques",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
