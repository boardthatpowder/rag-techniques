{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Translation: Step Back\n",
    "\n",
    "![step-back](../images/images-step-back.png)\n",
    "\n",
    "**Step-Back** is a technique that works by broadening a query to retrieve more general, high-level information before refining it for a specific answer. It takes a \"step back\" to provide the system with broader context, ensuring more complete and accurate results.\n",
    "\n",
    "### The Problem Step-Back Solves\n",
    "Sometimes, user queries can be overly specific or lack sufficient context, which may:\n",
    "- Limit the retrieval to only narrow or irrelevant information.\n",
    "- Prevent the system from understanding the query’s broader intent.\n",
    "\n",
    "**Step-Back** solves this by generating a more general version of the query first, retrieving broader context, and then using that context to refine the retrieval or generation process.\n",
    "\n",
    "### How Step-Back Works\n",
    "1. **Analyze the Query**:\n",
    "   - Identify if the query is too specific, lacks context, or could benefit from a broader starting point.\n",
    "   - Example:\n",
    "     - Original Query: \"How does OAuth 2.0 work in securing APIs?\"\n",
    "\n",
    "2. **Generate a Generalized Query**:\n",
    "   - Rewrite the original query to be more general or abstract, focusing on the broader topic.\n",
    "   - Example:\n",
    "     - General Query: \"What are the general principles of securing APIs?\"\n",
    "\n",
    "3. **Retrieve Broader Context**:\n",
    "   - Use the generalized query to retrieve high-level or foundational information about the topic.\n",
    "   - Example:\n",
    "     - Documents retrieved might include general API security practices, authentication methods, and common threats.\n",
    "\n",
    "4. **Refine the Response**:\n",
    "   - Use the retrieved broader context to either:\n",
    "     - Directly enhance the response generation.\n",
    "     - Refine the retrieval step further by adding the original specific query for a targeted follow-up.\n",
    "   - Example:\n",
    "     - Combine \"general principles of securing APIs\" with specifics about OAuth 2.0.\n",
    "\n",
    "5. **Generate the Final Output**:\n",
    "   - The combined context (broader and specific) is passed to the LLM to generate a well-informed, grounded response.\n",
    "\n",
    "### Why Step-Back Works\n",
    "- **Broadens Context**: Ensures the system has a comprehensive understanding of the topic before diving into specifics.\n",
    "- **Improves Retrieval**: Prevents overly specific queries from missing important related information.\n",
    "- **Grounds Generation**: Helps the system produce well-rounded and accurate responses.\n",
    "\n",
    "### Simple Example\n",
    "#### Query:\n",
    "*\"How does token expiry work in OAuth 2.0 for API security?\"*\n",
    "\n",
    "#### Without Step-Back:\n",
    "- The system might retrieve overly specific documents on token expiry without addressing the broader context of why token expiry is important in API security.\n",
    "\n",
    "#### With Step-Back:\n",
    "1. Generalized Query:\n",
    "   - \"What are the security features of OAuth 2.0?\"\n",
    "2. Retrieved Documents:\n",
    "   - General documents on OAuth 2.0, covering concepts like token-based authentication, refresh tokens, and expiry policies.\n",
    "3. Refine with Original Query:\n",
    "   - Use the specific query \"How does token expiry work?\" to find more detailed information.\n",
    "4. Combined Context:\n",
    "   - Broader understanding of OAuth 2.0 security combined with specific details about token expiry.\n",
    "5. Final Output:\n",
    "   - \"OAuth 2.0 provides token-based authentication to secure APIs. Token expiry ensures that access is time-limited, reducing the risk of token misuse. Refresh tokens can be used to issue new access tokens without compromising security.\"\n",
    "\n",
    "### Key Benefits of Step-Back\n",
    "- **Ensures Completeness**: Provides foundational knowledge before diving into specifics.\n",
    "- **Enhances Retrieval**: Prevents the system from missing key information by starting broad.\n",
    "- **Reduces Errors**: Avoids misinterpretations that can occur when overly specific queries lack context.\n",
    "\n",
    "In short, **Step-Back** is like zooming out to see the bigger picture before focusing on the finer details, ensuring a more complete and accurate response!\n",
    "\n",
    "![step back](../images/step%20back.png)\n",
    "\n",
    "Arxiv papers:\n",
    "\n",
    "- [Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models](https://arxiv.org/pdf/2310.06117)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'enable_langsmith' (bool)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "%run \"../Z - Common/setup.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_sample_data()\n",
    "split_docs = split_sample_data(docs)\n",
    "retriever = seed_sample_data(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining a prompt which includes few shot examples, and the chain to generate the step backed queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "# Few Shot Examples\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Sindel’s was born in what country?\",\n",
    "        \"output\": \"what is Jan Sindel’s personal history?\",\n",
    "    },\n",
    "]\n",
    "# We now transform these to example messages\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\",\n",
    "        ),\n",
    "        # Few shot examples\n",
    "        few_shot_prompt,\n",
    "        # New question\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain_generate_queries = prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the key parts of an AI system?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the main components of an LLM-powered autonomous agent system?\"\n",
    "chain_generate_queries.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and execute the overall chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Response prompt \n",
    "template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "# Answer:\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        # Retrieve context using the normal question\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        # Retrieve context using the step-back question\n",
    "        \"step_back_context\": chain_generate_queries | retriever,\n",
    "        # Pass on the question\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, an LLM-powered autonomous agent system has the following main components:\\n\\n1. LLM as the Core Controller (Brain)\\n- Functions as the central processing unit or \"brain\" of the agent system\\n- Goes beyond basic text generation to serve as a general problem solver\\n\\n2. Planning Component\\nThis includes two key aspects:\\n- Subgoal and decomposition\\n  * Breaks down large tasks into smaller, manageable subgoals\\n  * Enables efficient handling of complex tasks\\n- Reflection and refinement\\n  * Allows for self-criticism and self-reflection on past actions\\n  * Learns from mistakes\\n  * Refines actions for future steps\\n  * Improves the quality of final results\\n\\n3. Memory Component\\nWhile the specific details of the memory component aren\\'t elaborated in the given context, it is mentioned as one of the key components of the system.\\n\\nThe context also mentions examples of such systems like AutoGPT, GPT-Engineer, and BabyAGI as proof-of-concept demonstrations, with AutoGPT being highlighted as having a natural language interface, though with some reliability issues.\\n\\nThese components work together to create an autonomous system that can understand, plan, remember, and execute tasks while learning from its experiences.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=chain.invoke({\"question\": question})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results so we can compare later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results(\"step-back.txt\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-techniques",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
