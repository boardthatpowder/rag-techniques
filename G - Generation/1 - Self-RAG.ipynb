{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation: Self-RAG\n",
    "\n",
    "> Note: This notebook is based from [langgraph_self_rag_local.ipynb](https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_self_rag_local.ipynb), and has been updated to be Bedrock compatible.\n",
    "\n",
    "![Self-RAG](../images/images-self-RAG.png)\n",
    "\n",
    "**Self-RAG** is an advanced framework that enhances the capabilities of language models by enabling them to:\n",
    "\n",
    "- **Adaptively retrieve** external information as needed.\n",
    "- **Generate** contextually relevant responses.\n",
    "- **Critique** their own outputs to ensure accuracy and quality.\n",
    "\n",
    "This approach addresses limitations in traditional RAG systems, which may indiscriminately retrieve and incorporate a fixed number of passages, potentially leading to less relevant or unhelpful responses. \n",
    "\n",
    "**How Self-RAG Works:**\n",
    "\n",
    "1. **Adaptive Retrieval:**\n",
    "   - The model assesses each query to determine whether external information is necessary.\n",
    "   - It can choose to retrieve multiple times during the generation process or skip retrieval entirely if the internal knowledge suffices.\n",
    "2. **Generation:**\n",
    "   - Utilizes both internal knowledge and any retrieved external information to produce a response that is coherent and contextually appropriate.\n",
    "3. **Self-Critique:**\n",
    "   - Incorporates a self-reflection mechanism where the model evaluates its own output from multiple fine-grained aspects.\n",
    "   - Generates special \"critique tokens\" as part of the response to indicate confidence levels and potential areas of improvement.\n",
    "4. **Segment-wise Beam Search:**\n",
    "   - Employs a search strategy that selects the output maximizing utility based on diverse preferences, ensuring the final response aligns closely with user intent.\n",
    "\n",
    "**Benefits of Self-RAG:**\n",
    "\n",
    "- **Enhanced Factuality:** By retrieving information on demand and critiquing its own outputs, the model reduces the likelihood of generating incorrect or irrelevant responses.\n",
    "- **Versatility:** Adapts to diverse task requirements, tailoring its behavior to provide the most appropriate responses based on the context.\n",
    "- **Improved User Trust:** The self-reflection component allows the model to indicate its confidence and reasoning, fostering greater transparency and trustworthiness.\n",
    "\n",
    "**Example in Practice:**\n",
    "\n",
    "Imagine a user asks, \"What are the latest advancements in renewable energy technologies?\" The Self-RAG system would:\n",
    "\n",
    "- **Assess the Query:**\n",
    "  - Determine that external information is needed to provide an up-to-date response.\n",
    "- **Retrieve Information:**\n",
    "  - Fetch recent articles or papers on renewable energy advancements.\n",
    "- **Generate Response:**\n",
    "  - Combine internal knowledge with retrieved data to craft a comprehensive answer.\n",
    "- **Self-Critique:**\n",
    "  - Evaluate the response, adding critique tokens to indicate high confidence in the provided information.\n",
    "- **Deliver Output:**\n",
    "  - Present the user with a detailed, accurate, and current overview of advancements in renewable energy technologies.\n",
    "\n",
    "By implementing Self-RAG, language models become more adept at handling complex queries, providing responses that are not only accurate but also contextually nuanced and self-aware.\n",
    "\n",
    "![self-RAG](../images/self%20RAG.png)\n",
    "\n",
    "Arxiv paper:\n",
    "\n",
    "- [Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection](https://arxiv.org/abs/2310.11511)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../Z - Common/setup.ipynb\"\n",
    "\n",
    "!pip install -qU langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement some of these ideas from scratch using LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's index 3 blog posts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "doc_splits = split_sample_data(docs_list, chunk_size=250, chunk_overlap=0)\n",
    "retriever = seed_sample_data(doc_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the prompt and chain for the _Retrieval Grader_ step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "grade_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "    \n",
    "    Retrieved document:\n",
    "    \n",
    "    {document}\n",
    "    \n",
    "    User question: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"agent memory\"\n",
    "\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "# print(docs)\n",
    "doc_txt = docs[0].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the prompt and chain for the _Generate_ step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanhart/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-powered agents have two types of memory: short-term memory which involves in-context learning through prompt engineering, and long-term memory which uses external vector stores for retaining and retrieving information over extended periods. The long-term memory allows agents to store and access potentially infinite information that persists beyond individual conversations.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the prompt and chain for the _Hallucination Grader_ step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeHallucinations(binary_score='yes')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# Prompt\n",
    "hallucination_prompt = PromptTemplate (\n",
    "    template=\"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "     Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\n",
    "    \n",
    "    Set of facts:\n",
    "    \n",
    "    {documents}\n",
    "    \n",
    "    LLM generation: {generation}\n",
    "    \"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the prompt and chain for the _Answer Grader_ step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeAnswer(binary_score='yes')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data model\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# Prompt\n",
    "answer_prompt = PromptTemplate (\n",
    "    template=\"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\n",
    "    \n",
    "    User question: \n",
    "    \n",
    "    {question}\n",
    "    \n",
    "   LLM generation:\n",
    "    \n",
    "    {generation}\n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"generation\"],\n",
    ")\n",
    "\n",
    "answer_grader = answer_prompt | structured_llm_grader\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the prompt and chain for the _Question Rewriter_ step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Let me help improve this question. The input \"agent memory\" is very brief and lacks context, but seems to be asking about how agents store or maintain information.\\n\\nImproved question:\\n\"How do AI agents maintain and store memory or state information during interactions?\"\\n\\nThis reformulation:\\n1. Expands the concept of \"memory\" to include state management\\n2. Specifically references AI agents\\n3. Uses more specific technical terminology\\n4. Forms a complete, searchable question\\n5. Would better match relevant documents in a vector database'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt\n",
    "re_write_prompt = PromptTemplate (\n",
    "    template=\"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\n",
    "    \n",
    "    Here is the initial question:\n",
    "    \n",
    "    {question}\n",
    "    \n",
    "    Formulate an improved question.  \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create our graph that will use Self-RAG:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from IPython.display import Image, display\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()\n",
    "\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def run_graph(question):\n",
    "    inputs = {\"question\": question}\n",
    "    for output in app.stream(inputs):\n",
    "        for key, value in output.items():\n",
    "            # Node\n",
    "            pprint(f\"Node: '{key}':\")\n",
    "            # Optional: print full state at each node\n",
    "            # pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "        print(\"\\n---\\n\")\n",
    "\n",
    "    # Final generation\n",
    "    pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Node: 'retrieve':\"\n",
      "\n",
      "---\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "\"Node: 'grade_documents':\"\n",
      "\n",
      "---\n",
      "\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\"Node: 'generate':\"\n",
      "\n",
      "---\n",
      "\n",
      "('Based on the provided context, there are two main types of agent memory: '\n",
      " 'short-term memory (which involves in-context learning) and long-term memory '\n",
      " '(which uses external vector stores for retaining and retrieving information '\n",
      " 'over extended periods). While the context also mentions sensory memory in '\n",
      " 'human brains, this appears to be separate from the agent memory types being '\n",
      " 'discussed.')\n"
     ]
    }
   ],
   "source": [
    "run_graph(\"What are the types of agent memory?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Node: 'retrieve':\"\n",
      "\n",
      "---\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
      "\"Node: 'grade_documents':\"\n",
      "\n",
      "---\n",
      "\n",
      "---TRANSFORM QUERY---\n",
      "\"Node: 'transform_query':\"\n",
      "\n",
      "---\n",
      "\n",
      "---RETRIEVE---\n",
      "\"Node: 'retrieve':\"\n",
      "\n",
      "---\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
      "\"Node: 'grade_documents':\"\n",
      "\n",
      "---\n",
      "\n",
      "---TRANSFORM QUERY---\n",
      "\"Node: 'transform_query':\"\n",
      "\n",
      "---\n",
      "\n",
      "---RETRIEVE---\n",
      "\"Node: 'retrieve':\"\n",
      "\n",
      "---\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
      "\"Node: 'grade_documents':\"\n",
      "\n",
      "---\n",
      "\n",
      "---TRANSFORM QUERY---\n",
      "\"Node: 'transform_query':\"\n",
      "\n",
      "---\n",
      "\n",
      "---RETRIEVE---\n",
      "\"Node: 'retrieve':\"\n",
      "\n",
      "---\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
      "\"Node: 'grade_documents':\"\n",
      "\n",
      "---\n",
      "\n",
      "---TRANSFORM QUERY---\n",
      "\"Node: 'transform_query':\"\n",
      "\n",
      "---\n",
      "\n",
      "---RETRIEVE---\n",
      "\"Node: 'retrieve':\"\n",
      "\n",
      "---\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
      "\"Node: 'grade_documents':\"\n",
      "\n",
      "---\n",
      "\n",
      "---TRANSFORM QUERY---\n",
      "\"Node: 'transform_query':\"\n",
      "\n",
      "---\n",
      "\n",
      "---RETRIEVE---\n",
      "\"Node: 'retrieve':\"\n",
      "\n",
      "---\n",
      "\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "\"Node: 'grade_documents':\"\n",
      "\n",
      "---\n",
      "\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error raised by bedrock service: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.\n"
     ]
    },
    {
     "ename": "ThrottlingException",
     "evalue": "An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mThrottlingException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run_graph(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow does the AlphaCodium paper work?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[44], line 5\u001b[0m, in \u001b[0;36mrun_graph\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_graph\u001b[39m(question):\n\u001b[1;32m      4\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question}\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mstream(inputs):\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;66;03m# Node\u001b[39;00m\n\u001b[1;32m      8\u001b[0m             pprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1656\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1656\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1657\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1658\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1659\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1660\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1661\u001b[0m         ):\n\u001b[1;32m   1662\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1663\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langgraph/pregel/runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     run_with_retry(\n\u001b[1;32m    168\u001b[0m         t,\n\u001b[1;32m    169\u001b[0m         retry_policy,\n\u001b[1;32m    170\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    171\u001b[0m             CONFIG_KEY_SEND: partial(writer, t),\n\u001b[1;32m    172\u001b[0m             CONFIG_KEY_CALL: partial(call, t),\n\u001b[1;32m    173\u001b[0m         },\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langgraph/utils/runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    406\u001b[0m )\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[42], line 34\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     31\u001b[0m documents \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# RAG generation\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m generation \u001b[38;5;241m=\u001b[39m rag_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: documents, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question})\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m: documents, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m: generation}\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langchain_core/runnables/base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    285\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    287\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    288\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    289\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    290\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    291\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    292\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    293\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    294\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    295\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    647\u001b[0m ]\n\u001b[1;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[1;32m    634\u001b[0m                 m,\n\u001b[1;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    638\u001b[0m             )\n\u001b[1;32m    639\u001b[0m         )\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    853\u001b[0m         )\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langchain_aws/chat_models/bedrock.py:570\u001b[0m, in \u001b[0;36mChatBedrock._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop:\n\u001b[1;32m    568\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[0;32m--> 570\u001b[0m     completion, tool_calls, llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input_and_invoke(\n\u001b[1;32m    571\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    572\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    573\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m    574\u001b[0m         system\u001b[38;5;241m=\u001b[39msystem,\n\u001b[1;32m    575\u001b[0m         messages\u001b[38;5;241m=\u001b[39mformatted_messages,\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    577\u001b[0m     )\n\u001b[1;32m    578\u001b[0m \u001b[38;5;66;03m# usage metadata\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m usage \u001b[38;5;241m:=\u001b[39m llm_output\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langchain_aws/llms/bedrock.py:841\u001b[0m, in \u001b[0;36mBedrockBase._prepare_input_and_invoke\u001b[0;34m(self, prompt, system, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    840\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 841\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m     text \u001b[38;5;241m=\u001b[39m enforce_stop_tokens(text, stop)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/langchain_aws/llms/bedrock.py:827\u001b[0m, in \u001b[0;36mBedrockBase._prepare_input_and_invoke\u001b[0;34m(self, prompt, system, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m         request_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLED\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 827\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39minvoke_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options)\n\u001b[1;32m    829\u001b[0m     (\n\u001b[1;32m    830\u001b[0m         text,\n\u001b[1;32m    831\u001b[0m         tool_calls,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    834\u001b[0m         stop_reason,\n\u001b[1;32m    835\u001b[0m     ) \u001b[38;5;241m=\u001b[39m LLMInputOutputAdapter\u001b[38;5;241m.\u001b[39mprepare_output(provider, response)\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag-techniques/lib/python3.11/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mThrottlingException\u001b[0m: An error occurred (ThrottlingException) when calling the InvokeModel operation (reached max retries: 4): Too many requests, please wait before trying again.",
      "\u001b[0mDuring task with name 'generate' and id '63fed7c6-4d42-0c4f-78cc-88dff4b0b6a4'"
     ]
    }
   ],
   "source": [
    "run_graph(\"How does the AlphaCodium paper work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-techniques",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
